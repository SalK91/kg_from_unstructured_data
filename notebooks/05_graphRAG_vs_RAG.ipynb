{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21be6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "project_root = Path.cwd().parent   \n",
    "sys.path.append(str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3593337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_RAW = project_root / \"data\" / \"raw\"\n",
    "DATA_DIR_PROCESSED = project_root / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e00ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_rag import load_artifacts, retrieve_chunks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f20fea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "# Load all keys from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "print(\"Cohere key loaded:\", bool(COHERE_API_KEY))\n",
    "co = cohere.ClientV2(COHERE_API_KEY, log_warning_experimental_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfa300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ef23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = \"How did Dr. Watson first meet Sherlock Holmes, and which events and locations led to their shared lodgings at 221B Baker Street?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83ba39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Retrieval\n",
    "# Load RAG embeddings, index, and chunks\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_name)\n",
    "embeddings, index, chunks = load_artifacts(path=DATA_DIR_PROCESSED, prefix=\"simple_rag_\")\n",
    "rag_retrieved_chunks= retrieve_chunks(Question, index, chunks, model, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23fe8965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer not found.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\\n\\n\".join(rag_retrieved_chunks)\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant. Using ONLY the context below, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{Question}\n",
    "\n",
    "If you don't find the answer, ONLY state that answer not found. Do not try to make up an answer.\n",
    "\"\"\"\n",
    "response = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "response.dict()[\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d7345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "009da25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphRAG Retrieval\n",
    "# Load GraphRAG -Knowledge Graph\n",
    "with open(DATA_DIR_PROCESSED /\"entities.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    entities = json.load(f)\n",
    "with open(DATA_DIR_PROCESSED /\"relationships.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    relationships = json.load(f)\n",
    "kg_relationships = relationships\n",
    "unique_relations = set([rel['relation'] for rel in relationships])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b46e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: LLM generates a query to retrive data from KG ---\n",
    "graph_search_prompt = f\"\"\"\n",
    "You are an intelligent assistant that generates a Python function to retrieve KG facts.\n",
    "\n",
    "Inputs:\n",
    "- Entities: {entities}  # Full list with IDs and aliases\n",
    "- Unique Relations: {unique_relations}\n",
    "- Question: \"{Question}\"\n",
    "\n",
    "Instructions:\n",
    "1. First, map entity names or aliases to their IDs so you can filter KG facts correctly.\n",
    "2. Then, generate a Python function called `retrieve_kg_facts(kg_relationships)` that:\n",
    "   - Filters the KG relationships using entity IDs and the given relations.\n",
    "   - Returns relevant KG facts in the format: \"source_name → relation → target_name\".\n",
    "3. Do not assume facts that are not in the KG.\n",
    "4. Output ONLY the Python function code, no explanations and no extra text.\n",
    "5. function should take two arguments: kg_relationships and kg_entities.\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": graph_search_prompt}])\n",
    "\n",
    "function_code = response.dict()[\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f696a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_code = function_code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "kg_entities = entities\n",
    "kg_relationships = relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the function safely\n",
    "local_vars = {}\n",
    "exec(function_code, {}, local_vars)\n",
    "retrieved_facts = local_vars[\"retrieve_kg_facts\"](kg_relationships, kg_entities)\n",
    "print(\"Retrieved KG facts:\", retrieved_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69977546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3427d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved KG facts: ['Watson → meets → Sherlock Holmes', 'Sherlock Holmes → mentions → Baker Street']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
