{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08695ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "from time import sleep\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "947aee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_entities import finalize_entities_and_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50159089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "project_root = Path.cwd().parent   \n",
    "sys.path.append(str(project_root / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "743463f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_RAW = project_root / \"data\" / \"raw\"\n",
    "DATA_DIR_PROCESSED = project_root / \"data\" / \"processed\"\n",
    "PROMPTS_DIR = project_root / \"prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5189ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# LLM API\n",
    "# Load all keys from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "print(\"Cohere key loaded:\", bool(COHERE_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f679117",
   "metadata": {},
   "source": [
    "### Call LLM on each chunk to identify nodes and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1cd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.ClientV2(COHERE_API_KEY, log_warning_experimental_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a37c8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR_RAW /\"a_study_in_scarlet_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7629f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## chunks = chunks[:5]  # for testing, use only first 5 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090d8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base prompt\n",
    "prompt_base = open(PROMPTS_DIR /\"prompt_template.txt\").read()\n",
    "\n",
    "# Load the response schema\n",
    "with open(PROMPTS_DIR /\"response_schema.json\") as f:\n",
    "    response_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a98697bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/61\n",
      "Processing chunk 2/61\n",
      "Processing chunk 3/61\n",
      "Processing chunk 4/61\n",
      "Processing chunk 5/61\n",
      "Processing chunk 6/61\n",
      "Processing chunk 7/61\n",
      "Processing chunk 8/61\n",
      "Processing chunk 9/61\n",
      "Processing chunk 10/61\n",
      "Processing chunk 11/61\n",
      "Processing chunk 12/61\n",
      "Processing chunk 13/61\n",
      "Processing chunk 14/61\n",
      "Processing chunk 15/61\n",
      "Processing chunk 16/61\n",
      "Processing chunk 17/61\n",
      "Processing chunk 18/61\n",
      "Processing chunk 19/61\n",
      "Processing chunk 20/61\n",
      "Processing chunk 21/61\n",
      "Processing chunk 22/61\n",
      "Processing chunk 23/61\n",
      "Processing chunk 24/61\n",
      "Processing chunk 25/61\n",
      "Processing chunk 26/61\n",
      "Processing chunk 27/61\n",
      "Processing chunk 28/61\n",
      "Processing chunk 29/61\n",
      "Processing chunk 30/61\n",
      "Processing chunk 31/61\n",
      "Processing chunk 32/61\n",
      "Processing chunk 33/61\n",
      "Processing chunk 34/61\n",
      "Processing chunk 35/61\n",
      "Processing chunk 36/61\n",
      "Processing chunk 37/61\n",
      "Processing chunk 38/61\n",
      "Processing chunk 39/61\n",
      "Processing chunk 40/61\n",
      "Processing chunk 41/61\n",
      "Processing chunk 42/61\n",
      "Processing chunk 43/61\n",
      "Processing chunk 44/61\n",
      "Processing chunk 45/61\n",
      "Processing chunk 46/61\n",
      "Processing chunk 47/61\n",
      "Processing chunk 48/61\n",
      "Processing chunk 49/61\n",
      "Processing chunk 50/61\n",
      "Processing chunk 51/61\n",
      "Processing chunk 52/61\n",
      "Processing chunk 53/61\n",
      "Processing chunk 54/61\n",
      "Processing chunk 55/61\n",
      "Processing chunk 56/61\n",
      "Processing chunk 57/61\n",
      "Processing chunk 58/61\n",
      "Processing chunk 59/61\n",
      "Processing chunk 60/61\n",
      "Processing chunk 61/61\n"
     ]
    }
   ],
   "source": [
    "# Global lists of entities and relationships\n",
    "global_entities = []\n",
    "global_entity_map = {}      # name/alias -> id\n",
    "global_relationships = []\n",
    "global_relation_types = set()  # unique relation types\n",
    "\n",
    "existing_rels = set()       # (source_id, relation_type, target_id) tuples\n",
    "entity_counter = 1\n",
    "\n",
    "\n",
    "\n",
    "# Loop over each chunk\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
    "\n",
    "    # Prepare global lists\n",
    "    entity_list_str = json.dumps({\"entities\": global_entities}, ensure_ascii=False)\n",
    "    relation_list_str = json.dumps(list(global_relation_types), ensure_ascii=False)\n",
    "\n",
    "    # Update prompt with current chunk and global lists\n",
    "    prompt = prompt_base.replace(\"{CHUNK}\", chunk)\n",
    "    prompt = prompt.replace(\"{ENTITYLIST}\", entity_list_str)\n",
    "    prompt = prompt.replace(\"{RELATIONLIST}\", relation_list_str)\n",
    "\n",
    "    # Call the LLM\n",
    "    response = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": response_schema\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Parse model output\n",
    "    data = json.loads(response.dict()[\"message\"][\"content\"][0][\"text\"])\n",
    "    sleep(8)  # avoid rate limits\n",
    "\n",
    "    # Merge entities\n",
    "    for ent in data[\"entities\"]:\n",
    "        key = ent[\"name\"].lower()\n",
    "        if key in global_entity_map:\n",
    "            ent[\"id\"] = global_entity_map[key]\n",
    "        else:\n",
    "            ent_id = f\"e{entity_counter}\"\n",
    "            ent[\"id\"] = ent_id\n",
    "            global_entity_map[key] = ent_id\n",
    "            global_entities.append(ent)\n",
    "            entity_counter += 1\n",
    "\n",
    "    # Merge relationships (deduplicate and normalize)\n",
    "    for rel in data[\"relationships\"]:\n",
    "        src_id = global_entity_map.get(rel[\"source\"].lower(), rel[\"source\"])\n",
    "        tgt_id = global_entity_map.get(rel[\"target\"].lower(), rel[\"target\"])\n",
    "        rel_type = rel[\"relation\"].lower()\n",
    "\n",
    "        rel_key = (src_id, rel_type, tgt_id)\n",
    "        if rel_key not in existing_rels:\n",
    "            rel[\"source\"] = src_id\n",
    "            rel[\"target\"] = tgt_id\n",
    "            rel[\"relation\"] = rel_type\n",
    "            global_relationships.append(rel)\n",
    "            existing_rels.add(rel_key)\n",
    "            global_relation_types.add(rel_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806263b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d78c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Entity Resolution] Merged 'Dr. Watson' -> 'Watson' (sim=1.00)\n",
      "[Entity Resolution] Merged 'Sherlock Holmes' test' -> 'Sherlock Holmes' (sim=0.83)\n",
      "[Entity Resolution] Merged '221B, Baker Street' -> 'Baker Street' (sim=0.80)\n",
      "[Entity Resolution] Merged '221B Baker Street' -> 'Baker Street' (sim=0.83)\n",
      "[Entity Resolution] Merged 'Lestrade' -> 'Mr. Lestrade' (sim=1.00)\n",
      "[Entity Resolution] Merged 'murderer' -> 'the murderer' (sim=0.80)\n",
      "[Entity Resolution] Merged 'Rache' -> 'Rachel' (sim=0.91)\n",
      "[Entity Resolution] Merged 'Dr Watson' -> 'Watson' (sim=1.00)\n",
      "[Entity Resolution] Merged 'Mr. Stangerson' -> 'Stangerson' (sim=1.00)\n",
      "[Entity Resolution] Merged 'Drebber' -> 'Mr. Drebber' (sim=1.00)\n",
      "[Entity Resolution] Merged 'Enoch Drebber' -> 'Enoch J. Drebber' (sim=0.90)\n",
      "[Entity Resolution] Merged 'Leader' -> 'Lieder' (sim=0.83)\n",
      "[Entity Resolution] Merged 'Elders' -> 'Elder' (sim=0.91)\n",
      "[Entity Resolution] Merged 'Council of Four' -> 'Sacred Council of Four' (sim=0.81)\n",
      "[Entity Resolution] Merged 'Ferrier' -> 'terrier' (sim=0.86)\n",
      "[Entity Resolution] Merged 'the great mountains' -> 'the mountains' (sim=0.81)\n",
      "[Entity Resolution] Merged 'the horses' -> 'the house' (sim=0.84)\n",
      "[Entity Resolution] Merged 'the rock' -> 'the flock' (sim=0.82)\n",
      "[Entity Resolution] Merged 'the defile' -> 'the defiles' (sim=0.95)\n",
      "[Entity Resolution] Merged 'the grave' -> 'the ravine' (sim=0.84)\n",
      "[Entity Resolution] Merged 'Indians' -> 'India' (sim=0.83)\n",
      "[Entity Resolution] Merged 'Ferriers' -> 'terrier' (sim=0.80)\n",
      "[Entity Resolution] Merged 'Mormon' -> 'Mormons' (sim=0.92)\n",
      "[Entity Resolution] Merged 'mountains' -> 'the mountains' (sim=0.82)\n",
      "[Entity Resolution] Merged 'door' -> 'Doctor' (sim=0.80)\n",
      "[Entity Resolution] Merged 'Camberwell' -> 'Camberwell Road' (sim=0.80)\n"
     ]
    }
   ],
   "source": [
    "final_entities, final_relationships = finalize_entities_and_relationships(\n",
    "    global_entities,\n",
    "    global_relationships,\n",
    "    log=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eacd65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved entities and relationships to 'output/' folder\n"
     ]
    }
   ],
   "source": [
    "# Save entities\n",
    "with open(DATA_DIR_PROCESSED / \"entities.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_entities, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save relationships\n",
    "with open(DATA_DIR_PROCESSED / \"relationships.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_relationships, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved entities and relationships to 'output/' folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
