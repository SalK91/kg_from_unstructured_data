{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c08695ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import cohere\n",
    "from time import sleep\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "809bcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "# Add src/ to Python path so we can import modules\n",
    "project_root = Path.cwd().parent   \n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import your pipeline function\n",
    "from data_loader import fetch_and_clean, chunk_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "947aee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_entities import finalize_entities_and_relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "743463f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_RAW = project_root / \"data\" / \"raw\"\n",
    "DATA_DIR_PROCESSED = project_root / \"data\" / \"processed\"\n",
    "PROMPTS_DIR = project_root / \"prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5189ad46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# LLM API\n",
    "# Load all keys from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "print(\"Cohere key loaded:\", bool(COHERE_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f679117",
   "metadata": {},
   "source": [
    "### Call LLM on each chunk to identify nodes and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b1cd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.ClientV2(COHERE_API_KEY, log_warning_experimental_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a37c8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "with open(DATA_DIR_RAW / \"a_study_in_scarlet_chunks.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7629f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks = chunks[:5]  # for testing, use only first 5 chunks\n",
    "#chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "090d8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base prompt\n",
    "prompt_base = open(PROMPTS_DIR /\"prompt_template.txt\").read()\n",
    "\n",
    "# Load the response schema\n",
    "with open(PROMPTS_DIR /\"response_schema.json\") as f:\n",
    "    response_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98697bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/166\n",
      "Processing chunk 2/166\n",
      "Processing chunk 3/166\n",
      "Processing chunk 4/166\n",
      "Processing chunk 5/166\n",
      "Processing chunk 6/166\n",
      "Processing chunk 7/166\n",
      "Processing chunk 8/166\n",
      "Processing chunk 9/166\n",
      "Processing chunk 10/166\n",
      "Processing chunk 11/166\n",
      "Processing chunk 12/166\n",
      "Processing chunk 13/166\n",
      "Processing chunk 14/166\n",
      "Processing chunk 15/166\n",
      "Processing chunk 16/166\n",
      "Processing chunk 17/166\n",
      "Processing chunk 18/166\n",
      "Processing chunk 19/166\n",
      "Processing chunk 20/166\n",
      "Processing chunk 21/166\n",
      "Processing chunk 22/166\n",
      "Processing chunk 23/166\n",
      "Processing chunk 24/166\n",
      "Processing chunk 25/166\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "headers: {'content-type': 'text/html; charset=UTF-8', 'referrer-policy': 'no-referrer', 'content-length': '332', 'date': 'Tue, 02 Sep 2025 12:16:52 GMT', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 502, body: \n<html><head>\n<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n<title>502 Server Error</title>\n</head>\n<body text=#000000 bgcolor=#ffffff>\n<h1>Error: Server Error</h1>\n<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>\n<h2></h2>\n</body></html>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\cohere\\v2\\raw_client.py:709\u001b[0m, in \u001b[0;36mRawV2Client.chat\u001b[1;34m(self, model, messages, tools, strict_tools, documents, citation_options, response_format, safety_mode, max_tokens, stop_sequences, temperature, seed, frequency_penalty, presence_penalty, k, p, logprobs, tool_choice, thinking, raw_prompting, request_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GatewayTimeoutError(\n\u001b[0;32m    700\u001b[0m             headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders),\n\u001b[0;32m    701\u001b[0m             body\u001b[38;5;241m=\u001b[39mtyping\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    707\u001b[0m             ),\n\u001b[0;32m    708\u001b[0m         )\n\u001b[1;32m--> 709\u001b[0m     _response_json \u001b[38;5;241m=\u001b[39m \u001b[43m_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\httpx\\_models.py:832\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{RELATIONLIST}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, relation_list_str)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Call the LLM\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand-a-03-2025\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_schema\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Parse model output\u001b[39;00m\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\cohere\\client.py:35\u001b[0m, in \u001b[0;36mvalidate_args.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs: typing\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: typing\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m     34\u001b[0m     check_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\cohere\\v2\\client.py:366\u001b[0m, in \u001b[0;36mV2Client.chat\u001b[1;34m(self, model, messages, tools, strict_tools, documents, citation_options, response_format, safety_mode, max_tokens, stop_sequences, temperature, seed, frequency_penalty, presence_penalty, k, p, logprobs, tool_choice, thinking, raw_prompting, request_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m     request_options: typing\u001b[38;5;241m.\u001b[39mOptional[RequestOptions] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    244\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m V2ChatResponse:\n\u001b[0;32m    245\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    Generates a text response to a user message and streams it down, token by token. To learn how to use the Chat API with streaming follow our [Text Generation guides](https://docs.cohere.com/v2/docs/chat-api).\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     _response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict_tools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_tools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_prompting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prompting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32mc:\\Users\\salmank\\anaconda3\\envs\\pymc_env_5\\Lib\\site-packages\\cohere\\v2\\raw_client.py:711\u001b[0m, in \u001b[0;36mRawV2Client.chat\u001b[1;34m(self, model, messages, tools, strict_tools, documents, citation_options, response_format, safety_mode, max_tokens, stop_sequences, temperature, seed, frequency_penalty, presence_penalty, k, p, logprobs, tool_choice, thinking, raw_prompting, request_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m     _response_json \u001b[38;5;241m=\u001b[39m _response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(_response\u001b[38;5;241m.\u001b[39mheaders), body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[1;31mApiError\u001b[0m: headers: {'content-type': 'text/html; charset=UTF-8', 'referrer-policy': 'no-referrer', 'content-length': '332', 'date': 'Tue, 02 Sep 2025 12:16:52 GMT', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 502, body: \n<html><head>\n<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\">\n<title>502 Server Error</title>\n</head>\n<body text=#000000 bgcolor=#ffffff>\n<h1>Error: Server Error</h1>\n<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>\n<h2></h2>\n</body></html>\n"
     ]
    }
   ],
   "source": [
    "# Global lists of entities and relationships\n",
    "global_entities = []\n",
    "global_entity_map = {}      # name/alias -> id\n",
    "global_relationships = []\n",
    "global_relation_types = set()  # unique relation types\n",
    "\n",
    "existing_rels = set()       # (source_id, relation_type, target_id) tuples\n",
    "entity_counter = 1\n",
    "\n",
    "# Loop over each chunk\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1}/{len(chunks)}\")\n",
    "\n",
    "    # Prepare global lists\n",
    "    entity_list_str = json.dumps({\"entities\": global_entities}, ensure_ascii=False)\n",
    "    relation_list_str = json.dumps(list(global_relation_types), ensure_ascii=False)\n",
    "\n",
    "    chunk_text_for_prompt = f\"{chunk['text']}\"\n",
    "    # Update prompt with current chunk and global lists\n",
    "    prompt = prompt_base.replace(\"{CHUNK}\", chunk_text_for_prompt)\n",
    "    prompt = prompt.replace(\"{ENTITYLIST}\", entity_list_str)\n",
    "    prompt = prompt.replace(\"{RELATIONLIST}\", relation_list_str)\n",
    "\n",
    "    # Call the LLM\n",
    "    response = co.chat(\n",
    "        model=\"command-a-03-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": response_schema\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Parse model output\n",
    "    data = json.loads(response.dict()[\"message\"][\"content\"][0][\"text\"])\n",
    "    sleep(30)  # avoid rate limits\n",
    "\n",
    "    # Merge entities\n",
    "    for ent in data[\"entities\"]:\n",
    "        key = ent[\"name\"].lower()\n",
    "        if key in global_entity_map:\n",
    "            ent[\"id\"] = global_entity_map[key]\n",
    "        else:\n",
    "            ent_id = f\"e{entity_counter}\"\n",
    "            ent[\"id\"] = ent_id\n",
    "            ent[\"chunk_id\"] = chunk[\"id\"]\n",
    "            global_entity_map[key] = ent_id\n",
    "            global_entities.append(ent)\n",
    "            entity_counter += 1\n",
    "\n",
    "    # Merge relationships (deduplicate and normalize)\n",
    "    for rel in data[\"relationships\"]:\n",
    "        src_id = global_entity_map.get(rel[\"source\"].lower(), rel[\"source\"])\n",
    "        tgt_id = global_entity_map.get(rel[\"target\"].lower(), rel[\"target\"])\n",
    "        rel_type = rel[\"relation\"].lower()\n",
    "\n",
    "        rel_key = (src_id, rel_type, tgt_id)\n",
    "        if rel_key not in existing_rels:\n",
    "            rel[\"source\"] = src_id\n",
    "            rel[\"target\"] = tgt_id\n",
    "            rel[\"relation\"] = rel_type\n",
    "            rel[\"chunk_id\"] = chunk[\"id\"]\n",
    "            global_relationships.append(rel)\n",
    "            existing_rels.add(rel_key)\n",
    "            global_relation_types.add(rel_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'e1',\n",
       "  'name': 'Doctor of Medicine',\n",
       "  'type': 'Role',\n",
       "  'aliases': [],\n",
       "  'span': 'Doctor of Medicine',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e2',\n",
       "  'name': 'University of London',\n",
       "  'type': 'Institution',\n",
       "  'aliases': [],\n",
       "  'span': 'University of London',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e3',\n",
       "  'name': 'Netley',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Netley',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e4',\n",
       "  'name': 'Fifth Northumberland Fusiliers',\n",
       "  'type': 'Organization',\n",
       "  'aliases': ['Northumberland Fusiliers'],\n",
       "  'span': 'Fifth Northumberland Fusiliers',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e5',\n",
       "  'name': 'India',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'India',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e6',\n",
       "  'name': 'Afghanistan',\n",
       "  'type': 'Location',\n",
       "  'aliases': ['Afghan'],\n",
       "  'span': 'Afghanistan',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e7',\n",
       "  'name': 'Bombay',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Bombay',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e8',\n",
       "  'name': 'Candahar',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Candahar',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e9',\n",
       "  'name': 'Berkshires',\n",
       "  'type': 'Organization',\n",
       "  'aliases': [],\n",
       "  'span': 'Berkshires',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e10',\n",
       "  'name': 'Maiwand',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Maiwand',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e11',\n",
       "  'name': 'Murray',\n",
       "  'type': 'Person',\n",
       "  'aliases': [],\n",
       "  'span': 'Murray',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e12',\n",
       "  'name': 'Peshawar',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Peshawar',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e13',\n",
       "  'name': 'England',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'England',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e14',\n",
       "  'name': 'Assistant Surgeon',\n",
       "  'type': 'Role',\n",
       "  'aliases': [],\n",
       "  'span': 'Assistant Surgeon',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e15',\n",
       "  'name': 'surgeons in the army',\n",
       "  'type': 'Role',\n",
       "  'aliases': [],\n",
       "  'span': 'surgeons in the army',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e16',\n",
       "  'name': 'Jezail bullet',\n",
       "  'type': 'Object',\n",
       "  'aliases': [],\n",
       "  'span': 'Jezail bullet',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e17',\n",
       "  'name': 'Ghazis',\n",
       "  'type': 'Organization',\n",
       "  'aliases': [],\n",
       "  'span': 'Ghazis',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e18',\n",
       "  'name': 'British lines',\n",
       "  'type': 'Organization',\n",
       "  'aliases': [],\n",
       "  'span': 'British lines',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e19',\n",
       "  'name': 'enteric fever',\n",
       "  'type': 'Event',\n",
       "  'aliases': [],\n",
       "  'span': 'enteric fever',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e20',\n",
       "  'name': 'medical board',\n",
       "  'type': 'Organization',\n",
       "  'aliases': [],\n",
       "  'span': 'medical board',\n",
       "  'chunk_id': 'chunk_1'},\n",
       " {'id': 'e21',\n",
       "  'name': 'Stamford',\n",
       "  'type': 'Person',\n",
       "  'aliases': ['young Stamford'],\n",
       "  'span': 'Stamford',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e22',\n",
       "  'name': 'Criterion Bar',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Criterion Bar',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e23',\n",
       "  'name': 'Barts',\n",
       "  'type': 'Institution',\n",
       "  'aliases': [],\n",
       "  'span': 'Barts',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e24',\n",
       "  'name': 'Holborn Restaurant',\n",
       "  'type': 'Location',\n",
       "  'aliases': ['Holborn'],\n",
       "  'span': 'Holborn',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e25',\n",
       "  'name': 'London',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'London',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e26',\n",
       "  'name': 'Strand',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Strand',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e27',\n",
       "  'name': 'Portsmouth',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'Portsmouth',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e28',\n",
       "  'name': 'Dr Watson',\n",
       "  'type': 'Person',\n",
       "  'aliases': ['Watson'],\n",
       "  'span': 'Watson',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e29',\n",
       "  'name': 'Orontes',\n",
       "  'type': 'Vehicle',\n",
       "  'aliases': ['troopship Orontes'],\n",
       "  'span': 'Orontes',\n",
       "  'chunk_id': 'chunk_2'},\n",
       " {'id': 'e30',\n",
       "  'name': 'Sherlock Holmes',\n",
       "  'type': 'Person',\n",
       "  'aliases': [],\n",
       "  'span': 'Sherlock Holmes',\n",
       "  'chunk_id': 'chunk_3'},\n",
       " {'id': 'e31',\n",
       "  'name': 'chemical laboratory',\n",
       "  'type': 'Location',\n",
       "  'aliases': [],\n",
       "  'span': 'chemical laboratory',\n",
       "  'chunk_id': 'chunk_3'},\n",
       " {'id': 'e32',\n",
       "  'name': 'hospital',\n",
       "  'type': 'Institution',\n",
       "  'aliases': [],\n",
       "  'span': 'hospital',\n",
       "  'chunk_id': 'chunk_3'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d78c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_entities, final_relationships = finalize_entities_and_relationships(\n",
    "    global_entities,\n",
    "    global_relationships,\n",
    "    log=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef665c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eacd65fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved entities and relationships to 'output/' folder\n"
     ]
    }
   ],
   "source": [
    "# Save entities\n",
    "with open(DATA_DIR_PROCESSED / \"entities.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_entities, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save relationships\n",
    "with open(DATA_DIR_PROCESSED / \"relationships.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_relationships, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved entities and relationships to 'output/' folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
